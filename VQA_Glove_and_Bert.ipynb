{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VQA_Glove and Bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSQjrIsS0si6"
      },
      "source": [
        "# **1.DATA ACQUISITION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvG3FUuIQQLQ",
        "outputId": "cdb93d03-c6ff-44e5-a8b7-18e73e025a93"
      },
      "source": [
        "#required packages version for tensorflow and keras\r\n",
        "#%pip install tensorflow==1.13.1\r\n",
        "%pip install tensorflow==1.14\r\n",
        "!pip install keras==2.1.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 35kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.10.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 45.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.19.4)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.32.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.36.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.12.4)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 23.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14) (51.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.4.0)\n",
            "Installing collected packages: tensorflow-estimator, keras-applications, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorboard 2.4.0\n",
            "    Uninstalling tensorboard-2.4.0:\n",
            "      Successfully uninstalled tensorboard-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.0\n",
            "    Uninstalling tensorflow-2.4.0:\n",
            "      Successfully uninstalled tensorflow-2.4.0\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n",
            "Collecting keras==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/c2/b0c2ece713e754d1692aa432ad682751cd1ad6abf7500a534558b1fbfbe7/Keras-2.1.0-py2.py3-none-any.whl (302kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.0) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.0) (1.19.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.0) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.0) (1.15.0)\n",
            "\u001b[31mERROR: textgenrnn 1.4.1 has requirement keras>=2.1.5, but you'll have keras 2.1.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1jXXTK0yy4k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c45c11fe-a351-4c5f-a9a0-e694ce2c201d"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "matplotlib.use(u'nbAgg')\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# import spacy\n",
        "import scipy.io\n",
        "import gc\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle\n",
        "import json\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers.core import Dense, Dropout, Activation, Reshape\n",
        "from tensorflow.keras import Input\n",
        "#from keras.layers.recurrent import LSTM\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.python.keras.layers.merge import Concatenate\n",
        "from tensorflow.keras.models import model_from_json, Model,Sequential\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from collections import defaultdict\n",
        "import operator\n",
        "from tensorflow.python.keras.utils import np_utils, generic_utils\n",
        "#from progressbar import Bar, ETA, Percentage, ProgressBar\n",
        "from itertools import zip_longest\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer,one_hot\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.python.keras.layers import LSTM, BatchNormalization,concatenate,Flatten,Embedding,Dense,Dropout,MaxPooling2D,Reshape,CuDNNLSTM,SpatialDropout1D\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras import Model,Input\n",
        "from tensorflow.python.keras.layers.convolutional import Conv2D,Conv1D\n",
        "from tensorflow.keras import initializers \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "import tensorflow.keras.backend as k\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint,TensorBoard\n",
        "from time import time\n",
        "from tensorflow.keras.regularizers import l1,l2,l1_l2\n",
        "from scipy.sparse import hstack\n",
        "import tensorflow.keras\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "# import cv2\n",
        "%matplotlib inline\n",
        "#%tensorflow_version 1.x\n",
        "\n",
        "import os\n",
        "os.environ['DISABLE_COLAB_TF_IMPORT_HOOK'] = '1'\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7v3RAI8BULGp"
      },
      "source": [
        "#!wget https://vision.ece.vt.edu/vqa/release_data/mscoco/vqa/mscoco_train2014_annotations.json\r\n",
        "#!cp -r '/content/mscoco_train2014_annotations.json' '/content/drive/MyDrive/v2_Questions_Val_mscoco'\r\n",
        "#que = json.load(open('v2_OpenEnded_mscoco_train2014_questions.json', 'r'))\r\n",
        "#ans = json.load(open('v2_mscoco_train2014_annotations.json', 'r'))\r\n",
        "#v2_mscoco_val2014_annotations.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKbFUvT8RemH"
      },
      "source": [
        "que = json.load(open('/content/drive/MyDrive/v2_Questions_Val_mscoco/v2_OpenEnded_mscoco_val2014_questions.json', 'r'))\n",
        "ans = json.load(open('/content/drive/MyDrive/v2_Annotations_Val_mscoco.zip (Unzipped Files)/v2_mscoco_val2014_annotations.json', 'r'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AQaRsW-RflI",
        "outputId": "f27ac851-a6b1-42d1-9aa1-66200621e438"
      },
      "source": [
        "print(\"Total no. of question are\",len(que['questions']))\n",
        "print(\"Total no. of answers are\",len(ans['annotations']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total no. of question are 214354\n",
            "Total no. of answers are 214354\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSSO3J_GQEBW"
      },
      "source": [
        "from os import listdir\n",
        "image_dir = '/content/drive/MyDrive/val2015'\n",
        "images= listdir(image_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_7KjDlI1rv6",
        "outputId": "88e24ce9-9b5c-4376-81d0-476e4f0b3de8"
      },
      "source": [
        "print(\"Total number of images present in the dataset are\", len(images))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of images present in the dataset are 2053\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqK9dE8DPbwS",
        "outputId": "6af34d9b-bae7-4193-d7c4-b91dc8833329"
      },
      "source": [
        "# CONVERTING DATA FROM JASON TO PANDAS DATAFRAME\n",
        "subtype='val2014'\n",
        "data=[]\n",
        "imdir='%s/COCO_%s_%012d.jpg'\n",
        "for i in tqdm(range(len(ans['annotations']))):\n",
        "    answ=ans['annotations'][i]['multiple_choice_answer']\n",
        "    im_path=imdir%(subtype,subtype,ans['annotations'][i]['image_id'])\n",
        "    ques=que['questions'][i]['question']\n",
        "    data.append({'im_path':im_path,'ques':ques,'answ':answ})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 214354/214354 [00:00<00:00, 501249.04it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "bMjwJm_wPbwq",
        "outputId": "331abf5a-e95a-4dbe-e715-404a28aca5a7"
      },
      "source": [
        "total_data=pd.DataFrame(data)\n",
        "total_data.im_path = '/content/drive/MyDrive/'+total_data[\"im_path\"] \n",
        "total_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>im_path</th>\n",
              "      <th>ques</th>\n",
              "      <th>answ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/val2014/COCO_val2014_00...</td>\n",
              "      <td>Where is he looking?</td>\n",
              "      <td>down</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/val2014/COCO_val2014_00...</td>\n",
              "      <td>What are the people in the background doing?</td>\n",
              "      <td>watching</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/val2014/COCO_val2014_00...</td>\n",
              "      <td>What is he on top of?</td>\n",
              "      <td>picnic table</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/val2014/COCO_val2014_00...</td>\n",
              "      <td>What website copyrighted the picture?</td>\n",
              "      <td>foodiebakercom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/val2014/COCO_val2014_00...</td>\n",
              "      <td>Is this a creamy soup?</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             im_path  ...            answ\n",
              "0  /content/drive/MyDrive/val2014/COCO_val2014_00...  ...            down\n",
              "1  /content/drive/MyDrive/val2014/COCO_val2014_00...  ...        watching\n",
              "2  /content/drive/MyDrive/val2014/COCO_val2014_00...  ...    picnic table\n",
              "3  /content/drive/MyDrive/val2014/COCO_val2014_00...  ...  foodiebakercom\n",
              "4  /content/drive/MyDrive/val2014/COCO_val2014_00...  ...              no\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7J-rP9614H9",
        "outputId": "de9211fd-ee33-426d-92e8-3d9665622aab"
      },
      "source": [
        "total_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(214354, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMZjqQu_lf7C"
      },
      "source": [
        "# **PREPROCESSING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O1pUtQHPbw7"
      },
      "source": [
        "import re\n",
        "\n",
        "def decontracted(phrase):\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    return phrase"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwSvZhdJPbxA",
        "outputId": "874a20bb-2fc5-419c-a137-039d4d465a55"
      },
      "source": [
        "preprocessed_questions = []\n",
        "for question in tqdm(total_data['ques'].values):\n",
        "    que = decontracted(question) \n",
        "    preprocessed_questions.append(que.lower().strip())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 214354/214354 [00:01<00:00, 118295.83it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "kOh-B9_xPbxH",
        "outputId": "8b8d5e59-bb60-4c4d-a9bf-34d7e12eabc7"
      },
      "source": [
        "total_data['ques']=preprocessed_questions\n",
        "total_data.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>im_path</th>\n",
              "      <th>ques</th>\n",
              "      <th>answ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/val2014/COCO_val2014_00...</td>\n",
              "      <td>where is he looking?</td>\n",
              "      <td>down</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/val2014/COCO_val2014_00...</td>\n",
              "      <td>what are the people in the background doing?</td>\n",
              "      <td>watching</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             im_path  ...      answ\n",
              "0  /content/drive/MyDrive/val2014/COCO_val2014_00...  ...      down\n",
              "1  /content/drive/MyDrive/val2014/COCO_val2014_00...  ...  watching\n",
              "\n",
              "[2 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_x8ULtsnIAE"
      },
      "source": [
        "total_data=total_data.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOe_QGDpPbxd"
      },
      "source": [
        "a=pd.DataFrame(total_data['answ'].value_counts()[:2])\n",
        "ind=list(a.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMuACZg6PbyF",
        "outputId": "99c86879-24f9-4977-c6bb-1fc144ba8764"
      },
      "source": [
        "top_data=pd.DataFrame()\n",
        "for i in tqdm(ind):\n",
        "    top_data1=total_data[total_data.answ == i]\n",
        "    top_data=pd.concat([top_data,top_data1],ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 14.94it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBH29fPOPbyM",
        "outputId": "fb3241b3-ea52-4b11-c69d-53305c55f44b"
      },
      "source": [
        "print(\"Shape of data after considering top 2 answers is\",top_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data after considering top 2 answers is (80810, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZFeAY6BPbyZ"
      },
      "source": [
        "top_data=top_data.sample(40000).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDTe2to3zHFs",
        "outputId": "22f74f82-68d3-47c3-8a1e-14115ae88064"
      },
      "source": [
        "print(\"Shape of data after considering top 2 answers is\",top_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data after considering top 2 answers is (40000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "WoKBjMsxPbyg",
        "outputId": "ddc097d2-c74c-4030-9d8f-d6604f8c56c2"
      },
      "source": [
        "top_data.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>im_path</th>\n",
              "      <th>ques</th>\n",
              "      <th>answ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/val2014/COCO_val2014_00...</td>\n",
              "      <td>is the tram full of people?</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/val2014/COCO_val2014_00...</td>\n",
              "      <td>is this man riding a wave?</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             im_path  ... answ\n",
              "0  /content/drive/MyDrive/val2014/COCO_val2014_00...  ...  yes\n",
              "1  /content/drive/MyDrive/val2014/COCO_val2014_00...  ...  yes\n",
              "\n",
              "[2 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN9jSCIWma4A"
      },
      "source": [
        "# **Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFV5gjwBPbyn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "24a2b0b9-0d8f-495b-c568-5d4988556588"
      },
      "source": [
        "word_count = top_data['ques'].str.split().apply(len).value_counts()\n",
        "word_dict = dict(word_count)\n",
        "word_dict = dict(sorted(word_dict.items(), key=lambda kv: kv[1],reverse=True))\n",
        "\n",
        "\n",
        "ind = np.arange(len(word_dict))\n",
        "plt.figure(figsize=(20,5))\n",
        "p1 = plt.bar(ind, list(word_dict.values()))\n",
        "\n",
        "plt.ylabel('Number of questions')\n",
        "plt.xlabel('Number of words in questions')\n",
        "plt.title('Words for each question')\n",
        "plt.xticks(ind, list(word_dict.keys()))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9Lz5evaGNic"
      },
      "source": [
        "Observations:\n",
        "1. Most of the question length is 4 to 8 words.\n",
        "2. Maximum length of question is 22 words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "q-S4D-BEPby2",
        "outputId": "124b9253-fa8c-49e7-d926-3c253aa0e645"
      },
      "source": [
        "que_word_count = top_data['ques'].str.split().apply(len)\n",
        "plt.boxplot(que_word_count)\n",
        "plt.xticks([1],'questions')\n",
        "plt.ylabel('Words in questions')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw7GC7kjGxiY"
      },
      "source": [
        "Observations:\n",
        "1. 50% questions have 5 to 8 words.\n",
        "2. Most of the questions have less than 10 words although there are few questions having greater than 10 words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "rTExqWvbPbzF",
        "outputId": "3ae3e4cb-b9da-4dba-cd19-41bbf8cb89b6"
      },
      "source": [
        "word_count = top_data['answ'].value_counts()[0:20]\n",
        "word_dict = dict(word_count)\n",
        "word_dict = dict(sorted(word_dict.items(), key=lambda kv: kv[1],reverse=True))\n",
        "\n",
        "\n",
        "ind = np.arange(len(word_dict))\n",
        "plt.figure(figsize=(20,5))\n",
        "p1 = plt.bar(ind, list(word_dict.values()))\n",
        "\n",
        "plt.ylabel('Count')\n",
        "plt.xlabel('Top 20 answers')\n",
        "plt.title('Count of top 20 answers')\n",
        "plt.xticks(ind, list(word_dict.keys()))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5DtLBaMHl_C"
      },
      "source": [
        "Observations:\n",
        "1. Very large proportion of the answer have yes/no answer.\n",
        "2. Apart from binary answers  most common answes constists of either colors or numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9rEIfwwPbzL",
        "outputId": "ec90fc60-d4db-418c-9b40-b4bf6ceef830"
      },
      "source": [
        "cnt1= top_data[top_data['answ']=='yes']['answ'].count()+top_data[top_data['answ']=='no']['answ'].count()\n",
        "cnt2= len(top_data)-cnt1\n",
        "print(\"Total no of binary(yes/no) answers  :\",cnt1)\n",
        "print(\"% of binary answers                 :\",np.round(cnt1/len(top_data)*100,2))\n",
        "print(\"Total no of multiple answers        :\",cnt2)\n",
        "print(\"% of multiple answers               :\",np.round(cnt2/len(top_data)*100,2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total no of binary(yes/no) answers  : 40000\n",
            "% of binary answers                 : 100.0\n",
            "Total no of multiple answers        : 0\n",
            "% of multiple answers               : 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "wB_TkWc7PbzX",
        "outputId": "1767311a-23dc-4409-8ef8-2bc319350f3e"
      },
      "source": [
        "word_count = top_data['answ'].str.split().apply(len).value_counts()\n",
        "word_dict = dict(word_count)\n",
        "word_dict = dict(sorted(word_dict.items(), key=lambda kv: kv[1],reverse=True))\n",
        "\n",
        "\n",
        "ind = np.arange(len(word_dict))\n",
        "plt.figure(figsize=(20,5))\n",
        "p1 = plt.bar(ind, list(word_dict.values()))\n",
        "\n",
        "plt.ylabel('Number of answers')\n",
        "plt.xlabel('Number of words in answers')\n",
        "plt.title('Words for each answer')\n",
        "plt.xticks(ind, list(word_dict.keys()))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCWugHqQIjpk"
      },
      "source": [
        "Observations:\n",
        "1. Almost 95% answers are one word answers although few questions have 2,3 and 4 word answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aTWvl8WPbz4"
      },
      "source": [
        "\n",
        "#top_data.drop(['answ'],axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mFgvDw4QAtJ"
      },
      "source": [
        "x_train=pd.read_csv('/content/drive/MyDrive/data/x_train.csv')\n",
        "x_test=pd.read_csv('/content/drive/MyDrive/data/x_test.csv')\n",
        "y_train=pd.read_csv('/content/drive/MyDrive/data/y_train.csv')\n",
        "y_test=pd.read_csv('/content/drive/MyDrive/data/y_test.csv')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dNg5dTMZWw2"
      },
      "source": [
        "y_train.drop(['Unnamed: 0'],axis=1,inplace=True)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL31fisXZkfa"
      },
      "source": [
        "y_test.drop(['Unnamed: 0'],axis=1,inplace=True)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnOLmE2212FL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acdef218-2cd0-40a6-dc9b-552d55c2d196"
      },
      "source": [
        "!pip uninstall keras-preprocessing"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling Keras-Preprocessing-1.1.2:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/Keras_Preprocessing-1.1.2.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/keras_preprocessing/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled Keras-Preprocessing-1.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFJLpz0z12BF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "e301527a-7177-480d-e658-dfefff95df0e"
      },
      "source": [
        "pip install git+https://github.com/keras-team/keras-preprocessing.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/keras-team/keras-preprocessing.git\n",
            "  Cloning https://github.com/keras-team/keras-preprocessing.git to /tmp/pip-req-build-12ig7fe3\n",
            "  Running command git clone -q https://github.com/keras-team/keras-preprocessing.git /tmp/pip-req-build-12ig7fe3\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras-Preprocessing==1.1.2) (1.19.4)\n",
            "Building wheels for collected packages: Keras-Preprocessing\n",
            "  Building wheel for Keras-Preprocessing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Keras-Preprocessing: filename=Keras_Preprocessing-1.1.2-cp36-none-any.whl size=43074 sha256=07c0d3ef4d13ca80d35bc18e402edfac14d4cad1176b241a2356126c5dc41c0e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zrcu7w86/wheels/03/a0/39/171f6040d36f36c71168dc69afa81334351b20955dc36ce932\n",
            "Successfully built Keras-Preprocessing\n",
            "Installing collected packages: Keras-Preprocessing\n",
            "Successfully installed Keras-Preprocessing-1.1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras_preprocessing"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5A6-WGC2lRP"
      },
      "source": [
        "from keras_preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcXxKO6eWf1S"
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import load_img,img_to_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEwPBX2woeTt"
      },
      "source": [
        "# **ENCODING QUESTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdyRV8BHvxmm"
      },
      "source": [
        "def textokenizer(text):\n",
        "  max_length = 24\n",
        "  tok = Tokenizer()\n",
        "  tok.fit_on_texts(x_train['ques'])\n",
        "  vocab_size = len(tok.word_index) + 1\n",
        "  #print('Total unique words in the x_train',vocab_size)\n",
        "  encoded_text = tok.texts_to_sequences(text)\n",
        "  padded_text = pad_sequences(encoded_text, maxlen=max_length)  #padding zeros at the begining of each question so that each sequence will have same length\n",
        "  #print(padded_text.shape)\n",
        "  return padded_text, tok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv8thPonfhPG"
      },
      "source": [
        "#!wget http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\r\n",
        "#!cp -r '/content/glove.6B.zip' '/content/drive/MyDrive/data'\r\n",
        "#!unzip /content/drive/MyDrive/data/glove.6B.zip\r\n",
        "#!cp -r '/content/glove.6B.300d.txt' '/content/drive/MyDrive/data'\r\n",
        "#!unzip '/content/drive/MyDrive/data/glove.840B.300d.pkl.zip'\r\n",
        "#!cp -r '/content/glove.840B.300d.pkl' '/content/drive/MyDrive/data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oCBcfaIlf04"
      },
      "source": [
        "#from gensim.scripts.glove2word2vec import glove2word2vec\r\n",
        "#glove2word2vec(glove_input_file=\"/content/drive/MyDrive/data/glove.6B.300d.txt\", word2vec_output_file=\"gensim_glove_vectors.txt\")\r\n",
        "#!cp -r '/content/gensim_glove_vectors.txt' '/content/drive/MyDrive/data'\r\n",
        "#from gensim.models.keyedvectors import KeyedVectors\r\n",
        "#glove_model = KeyedVectors.load_word2vec_format(\"/content/drive/MyDrive/data/gensim_glove_vectors.txt\", binary=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np4VtIL7Pb1C"
      },
      "source": [
        "#Each token is represented using 300-dim vector using pre-trained GloVe representation.\n",
        "with open('/content/drive/MyDrive/data/glove.840B.300d.pkl', 'rb') as f:\n",
        "    model = pickle.load(f)\n",
        "    glove_words =  set(model.keys())\n",
        "# for train\n",
        "_,tok = textokenizer(x_train['ques'])\n",
        "vocab_size = len(tok.word_index) + 1\n",
        "embedding_matrix_train = np.zeros((vocab_size, 300))\n",
        "for word, i in tok.word_index.items():\n",
        "    if word in glove_words:\n",
        "        embedding_vector = model[word]\n",
        "        embedding_matrix_train[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTyTuxMtPb1G",
        "outputId": "d492c3f3-a961-4cff-f1d1-cdf15267c34e"
      },
      "source": [
        "print(\"embedding matrix shape\",embedding_matrix_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embedding matrix shape (112, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSnBXE99qRF0"
      },
      "source": [
        "# **ENCODING ANSWERS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8ja_jPdPb1M"
      },
      "source": [
        "def optokens(classes):\n",
        "  from sklearn.preprocessing import OneHotEncoder\n",
        "  ohe=OneHotEncoder(handle_unknown='ignore')\n",
        "  ohe.fit(y_train.values.reshape(-1,1))\n",
        "  optoken=ohe.transform(classes.values.reshape(-1,1)).toarray()\n",
        "  return optoken, ohe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYhLxSc6cPyk"
      },
      "source": [
        "_,ohe=optokens(x_train['answ'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_L17hI9cJel"
      },
      "source": [
        "pickle.dump(ohe,open('/content/drive/MyDrive/data/ohe.pkl','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zjb2TyOrHJp"
      },
      "source": [
        "# **CREATING DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji5a56YNAAGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f977fc08-72d7-4746-803f-17874d671fa3"
      },
      "source": [
        "from tensorflow.keras.layers import MaxPooling2D,Conv2D,Input,Add,MaxPool2D,Flatten,AveragePooling2D,Dense,BatchNormalization,ZeroPadding2D,Activation,Concatenate,UpSampling2D\n",
        "from tensorflow.keras.models import Model\n",
        "model = VGG16(weights='imagenet')\n",
        "feature_model = Model(inputs=model.inputs, outputs=model.layers[-2].output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 12s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2eq8Df6247Z",
        "outputId": "e25f8000-6be7-44a4-dec7-174539070be4"
      },
      "source": [
        "len(set(top_data['im_path'].tolist()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUhyGKvADW8f"
      },
      "source": [
        "def parse_function(filename):\n",
        "    image_string = tf.io.read_file(filename)\n",
        "    #Don't use tf.image.decode_image, or the output shape will be undefined\n",
        "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
        "    #This will convert to float values in [0, 1]\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    image = tf.image.resize(image, [224, 224])\n",
        "    return  image, filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qflEZWSMFjWj",
        "outputId": "9b1cc667-d212-466d-a759-7e8fa23625e7"
      },
      "source": [
        "img_fl = sorted(set(top_data['im_path'].tolist()))\r\n",
        "img_fl[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/val2014/COCO_val2014_000000000196.jpg'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP1hcZKxDRDt",
        "outputId": "2270562c-dd7e-492e-8f3e-bc2faa43f35c"
      },
      "source": [
        "img_fl=sorted(set(top_data['im_path'].tolist()))\n",
        "img_data_tr=tf.data.Dataset.from_tensor_slices(img_fl)\n",
        "img_data_tr=img_data_tr.map(parse_function,num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(32).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "for img, path in tqdm(img_data_tr):\n",
        "  batch_features = feature_model(img)\n",
        "  #batch_features = tf.reshape(batch_features,(batch_features.shape[0], -1, batch_features.shape[3]))\n",
        "\n",
        "  for bf, p in zip(batch_features, path):\n",
        "    path_of_feature = p.numpy().decode(\"utf-8\")\n",
        "    np.save(path_of_feature, bf.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1it [00:20, 20.03s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5ChnAjleFFu"
      },
      "source": [
        "ques_train , _ =textokenizer(x_train['ques'])\n",
        "answ_train , _ =optokens(x_train['answ'])\n",
        "ques_train=ques_train.tolist()\n",
        "answ_train=answ_train.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTn9Oz46Wa3H"
      },
      "source": [
        "ques_train=ques_train.tolist()\n",
        "answ_train=answ_train.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v67TlbwdNtS"
      },
      "source": [
        "def map_func(img_name, question):\n",
        "  img_tensor = np.load(img_name.decode('utf-8')+'.npy')\n",
        "  return img_tensor, question"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43OT_04vovo9"
      },
      "source": [
        "img_fl=x_train['im_path'].tolist()\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((img_fl, ques_train))\n",
        "\n",
        "# Use map to load the numpy files in parallel\n",
        "train_dataset = train_dataset.map(lambda item1, item2: tf.numpy_function(\n",
        "          map_func, [item1, item2], [tf.float32, tf.int32]),\n",
        "          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "op_train_dataset = tf.data.Dataset.from_tensor_slices(answ_train)\n",
        "train_dataset=tf.data.Dataset.zip((train_dataset,op_train_dataset))\n",
        "train_dataset = train_dataset.batch(1000)\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LUSigJ1lKOY"
      },
      "source": [
        "ques_test,_=textokenizer(x_test['ques'])\n",
        "answ_test,_=optokens(x_test['answ'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R8Ty2DnWyLd"
      },
      "source": [
        "ques_test=ques_test.tolist()\n",
        "answ_test=answ_test.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGlztwF6diSr"
      },
      "source": [
        "img_fl_te=x_test['im_path'].tolist()\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((img_fl_te, ques_test))\n",
        "# Use map to load the numpy files in parallel\n",
        "test_dataset = test_dataset.map(lambda item1, item2: tf.numpy_function(\n",
        "          map_func, [item1, item2], [tf.float32, tf.int32]),\n",
        "          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "op_test_dataset = tf.data.Dataset.from_tensor_slices(answ_test)\n",
        "test_dataset=tf.data.Dataset.zip((test_dataset,op_test_dataset))\n",
        "test_dataset = test_dataset.batch(1000)\n",
        "test_dataset = test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-xe4_Z0uW8D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d758265c-0dd8-4e62-d411-92e778906f00"
      },
      "source": [
        "%who"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Activation\t Add\t AveragePooling2D\t BatchNormalization\t Callback\t Concatenate\t Conv1D\t Conv2D\t CountVectorizer\t \n",
            "CuDNNLSTM\t Dense\t Dropout\t EarlyStopping\t Embedding\t Flatten\t ImageDataGenerator\t Input\t LSTM\t \n",
            "LabelEncoder\t MaxPool2D\t MaxPooling2D\t Model\t ModelCheckpoint\t Reshape\t Sequential\t SpatialDropout1D\t TensorBoard\t \n",
            "TfidfVectorizer\t Tokenizer\t UpSampling2D\t VGG16\t ZeroPadding2D\t a\t ans\t answ\t answ_test\t \n",
            "answ_train\t batch_features\t bf\t cnt1\t cnt2\t concatenate\t data\t data_subset\t datetime\t \n",
            "decontracted\t defaultdict\t drive\t embedding_matrix_train\t embedding_vector\t f\t feature_model\t files_list\t gc\t \n",
            "generic_utils\t glove_words\t hstack\t i\t im_path\t image\t image_dir\t images\t imdir\t \n",
            "img\t img_data_tr\t img_fl\t img_fl_te\t img_to_array\t ind\t initializers\t json\t k\t \n",
            "l1\t l1_l2\t l2\t listdir\t load_img\t load_model\t map_func\t matplotlib\t model\t \n",
            "model_from_json\t np\t np_utils\t ohe\t one_hot\t op_test_dataset\t op_train_dataset\t operator\t optokens\t \n",
            "os\t p\t p1\t pad_sequences\t parse_function\t path\t path_of_feature\t pd\t pickle\t \n",
            "plot_model\t plt\t preprocess_input\t preprocessed_questions\t que\t que_word_count\t ques\t ques_test\t ques_train\t \n",
            "question\t re\t roc_auc_score\t scipy\t sns\t subtype\t tensorflow\t test_dataset\t textokenizer\t \n",
            "tf\t time\t tok\t top_data\t top_data1\t total_data\t tqdm\t train_dataset\t train_test_split\t \n",
            "vocab_size\t warnings\t word\t word_count\t word_dict\t x_test\t x_train\t y\t y_test\t \n",
            "y_train\t zip_longest\t \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjg8vDE3xOkC"
      },
      "source": [
        "# **MODEL 1** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uefGhIBHIg-J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02e82712-777c-4162-96ea-cbf9e0518b51"
      },
      "source": [
        "#IMAGE MODEL\n",
        "im_input = Input(shape=(4096,), name = \"im_input\")\n",
        "#flat = Flatten()(im_input)\n",
        "image_model=Dense(1024,activation='relu',kernel_initializer=initializers.he_normal(seed=42))(im_input)\n",
        "image_model=Model(inputs=im_input,outputs=image_model)\n",
        "image_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "im_input (InputLayer)        [(None, 4096)]            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              4195328   \n",
            "=================================================================\n",
            "Total params: 4,195,328\n",
            "Trainable params: 4,195,328\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6gyBCufFG5v"
      },
      "source": [
        "max_length=24\n",
        "vocab_size=embedding_matrix_train.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH5dup7cPb1y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57af5520-2d90-4e1a-d055-ed44a07820ea"
      },
      "source": [
        "#QUESTION MODEL\n",
        "\n",
        "from tensorflow.python.keras.layers import LSTM\n",
        "ques_input = Input(shape=(max_length,), name = \"ques_input\")\n",
        "e1 =Embedding(vocab_size, 300, weights=[embedding_matrix_train], input_length=max_length,trainable=False)(ques_input)\n",
        "l1= LSTM(64,kernel_initializer=initializers.he_normal(seed=42),kernel_regularizer=l2(0.001),return_sequences=True)(e1)\n",
        "l2= LSTM(64,kernel_initializer=initializers.he_normal(seed=42),kernel_regularizer=l2(0.001),return_sequences=True)(l1)\n",
        "#l1= LeakyReLU(alpha = 0.3)(l1)\n",
        "f1= Flatten(name='flatten_1')(l2)\n",
        "question_model=Dense(1024,activation='relu',kernel_initializer=initializers.he_normal(seed=42))(f1)\n",
        "question_model = Model(inputs=ques_input, outputs=question_model)\n",
        "question_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "ques_input (InputLayer)      [(None, 24)]              0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 24, 300)           33600     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 24, 64)            93440     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 24, 64)            33024     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1536)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              1573888   \n",
            "=================================================================\n",
            "Total params: 1,733,952\n",
            "Trainable params: 1,700,352\n",
            "Non-trainable params: 33,600\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac-cfz4OPb3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "841f550c-36ab-43bd-98ac-63fc71235e2f"
      },
      "source": [
        "#COMBINING FEATURES AND MAKING FINAL MODEL FOR PREDICTION\n",
        "from tensorflow.keras.layers import multiply\n",
        "input_model=multiply([image_model.layers[-1].output,question_model.layers[-1].output])\n",
        "d1=BatchNormalization()(input_model)\n",
        "d1 = Dropout(0.5)(d1)\n",
        "d1=Dense(1000,activation='relu',kernel_initializer=initializers.he_normal(seed=42))(d1)\n",
        "final_output = Dense(2, kernel_initializer=initializers.he_normal(seed=42),activation='softmax')(d1)\n",
        "final_model = Model(inputs=[im_input,ques_input], outputs=final_output)\n",
        "print(final_model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "ques_input (InputLayer)         [(None, 24)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 24, 300)      33600       ques_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 24, 64)       93440       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 24, 64)       33024       lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "im_input (InputLayer)           [(None, 4096)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 1536)         0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         4195328     im_input[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1024)         1573888     flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply (Multiply)             (None, 1024)         0           dense[0][0]                      \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 1024)         4096        multiply[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1000)         1025000     dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            2002        dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 6,960,378\n",
            "Trainable params: 6,924,730\n",
            "Non-trainable params: 35,648\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52TV9HCrpLYR"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "!rm -rf ./logs1/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "878M6CmiPb4j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c88dca8-9d3d-4097-b332-3bf4c75ed074"
      },
      "source": [
        "checkpoint = ModelCheckpoint(\"/content/drive/MyDrive/data/basic_model11.h5\",\n",
        "                             monitor=\"val_loss\",\n",
        "                             mode=\"min\",\n",
        "                             save_best_only = True,\n",
        "                             verbose=1)\n",
        "earlystop= EarlyStopping(monitor = 'val_loss', \n",
        "                            mode=\"min\",\n",
        "                            min_delta = 0, \n",
        "                            patience = 5,\n",
        "                            verbose = 1)\n",
        "\n",
        "tensorboard = TensorBoard(log_dir='logs1',histogram_freq=1,write_grads=True)\n",
        "\n",
        "callbacks = [checkpoint,earlystop,tensorboard]\n",
        "#callbacks = [checkpoint,tensorboard]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Weight and gradient histograms not supported for eagerexecution, setting `histogram_freq` to `0`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOFZqkfhUcFg"
      },
      "source": [
        "#final_model=load_model('/content/drive/My Drive/basic_model1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg93PotrUXg-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67af3478-6825-40b8-dc1c-8659d21bd04c"
      },
      "source": [
        "final_model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy']) \n",
        "h1 = final_model.fit(train_dataset, epochs=20, verbose=1,workers=-1, use_multiprocessing=-1,callbacks=callbacks, validation_data=test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.69237, saving model to /content/drive/MyDrive/data/basic_model11.h5\n",
            "1/1 [==============================] - 6s 6s/step - loss: 1.7089 - acc: 0.4474 - val_loss: 1.6924 - val_acc: 0.5882\n",
            "Epoch 2/20\n",
            "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.544725). Check your callbacks.\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.69237 to 1.68391, saving model to /content/drive/MyDrive/data/basic_model11.h5\n",
            "1/1 [==============================] - 1s 995ms/step - loss: 1.4392 - acc: 0.8158 - val_loss: 1.6839 - val_acc: 0.5882\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 1.68391\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 1.2977 - acc: 0.8684 - val_loss: 1.8295 - val_acc: 0.5882\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 1.68391\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 1.1631 - acc: 0.9474 - val_loss: 2.1788 - val_acc: 0.5882\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 1.68391\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 1.2333 - acc: 0.8947 - val_loss: 2.3465 - val_acc: 0.5882\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 1.68391\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 1.0420 - acc: 1.0000 - val_loss: 2.5264 - val_acc: 0.5882\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.68391\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 1.0510 - acc: 0.9474 - val_loss: 2.8188 - val_acc: 0.5882\n",
            "Epoch 00007: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEPgsV_kiPko"
      },
      "source": [
        "# **MODEL 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuOg4MieZ_Je"
      },
      "source": [
        "## **Importing Essential Libraries for Model 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYIVp2bTfwSl"
      },
      "source": [
        "!pip install bert-for-tf2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yaq5OEBQdwTx"
      },
      "source": [
        "import bert\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qC2lQUzdwg6"
      },
      "source": [
        "model_name = \"uncased_L-12_H-768_A-12\"\n",
        "model_dir = bert.fetch_google_bert_model(model_name, \".models\")\n",
        "model_ckpt = os.path.join(model_dir, \"bert_model.ckpt\")\n",
        "\n",
        "bert_params = bert.params_from_pretrained_ckpt(model_dir)\n",
        "l_bert = bert.BertModelLayer.from_params(bert_params, name=\"bert\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWKPk3MQrPUU"
      },
      "source": [
        "!pip install pytorch_pretrained_bert pytorch-nlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW0JxIEnaZD7"
      },
      "source": [
        "## **Preparing Dataset for Model 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv8JEpLPrD0M"
      },
      "source": [
        "from pytorch_pretrained_bert import BertTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLad-vOzqXob"
      },
      "source": [
        "#BertTokenizer=bert.bert_tokenization.FullTokenizer\r\n",
        "#tokenizer=BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tut1XjaC1p5"
      },
      "source": [
        "#!pip install pytorch-transformers\r\n",
        "!pip uninstall transformers\r\n",
        "!pip install transformers==3.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVPZcjndCq6b"
      },
      "source": [
        "from transformers import BertTokenizer, BertModel\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\r\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8pZwFrusEMy"
      },
      "source": [
        "train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:24] + ['[SEP]'], x_train['ques'].tolist()))\n",
        "test_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:24] + ['[SEP]'], x_test['ques'].tolist()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlYhtJxguhvB"
      },
      "source": [
        "train_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, train_tokens)), maxlen=24, truncating=\"post\", padding=\"pre\", dtype=\"int\")\n",
        "test_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, test_tokens)), maxlen=24, truncating=\"post\", padding=\"pre\", dtype=\"int\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbj3LoZpvXzU"
      },
      "source": [
        "img_fl=x_train['im_path'].tolist()\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((img_fl, train_tokens_ids))\n",
        "\n",
        "# Use map to load the numpy files in parallel\n",
        "train_dataset = train_dataset.map(lambda item1, item2: tf.numpy_function(\n",
        "          map_func, [item1, item2], [tf.float32, tf.int64]),\n",
        "          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "op_train_dataset = tf.data.Dataset.from_tensor_slices(answ_train)\n",
        "train_dataset=tf.data.Dataset.zip((train_dataset,op_train_dataset))\n",
        "train_dataset = train_dataset.batch(1000)\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2cpZFdlvzYt"
      },
      "source": [
        "img_fl_te=x_test['im_path'].tolist()\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((img_fl_te, test_tokens_ids))\n",
        "# Use map to load the numpy files in parallel\n",
        "test_dataset = test_dataset.map(lambda item1, item2: tf.numpy_function(\n",
        "          map_func, [item1, item2], [tf.float32, tf.int64]),\n",
        "          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "op_test_dataset = tf.data.Dataset.from_tensor_slices(answ_test)\n",
        "test_dataset=tf.data.Dataset.zip((test_dataset,op_test_dataset))\n",
        "test_dataset = test_dataset.batch(1000)\n",
        "test_dataset = test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pmg2q35uahYf"
      },
      "source": [
        "## **Model 2 training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8zwuw_7d2JB"
      },
      "source": [
        "l_bert.trainable=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "solS4DwJd7Z8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22b55e1a-f661-41a1-86b5-1b0bfbde0924"
      },
      "source": [
        "ques_inp = tf.keras.layers.Input(shape=(24,))\n",
        "embed = l_bert(ques_inp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method BertModelLayer.call of <bert.model.BertModelLayer object at 0x7ff789ffaf98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BertModelLayer.call of <bert.model.BertModelLayer object at 0x7ff789ffaf98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method BertModelLayer.call of <bert.model.BertModelLayer object at 0x7ff789ffaf98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BertModelLayer.call of <bert.model.BertModelLayer object at 0x7ff789ffaf98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BertEmbeddingsLayer.call of <bert.embeddings.BertEmbeddingsLayer object at 0x7ff789fff6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BertEmbeddingsLayer.call of <bert.embeddings.BertEmbeddingsLayer object at 0x7ff789fff6d8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method BertEmbeddingsLayer.call of <bert.embeddings.BertEmbeddingsLayer object at 0x7ff789fff6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BertEmbeddingsLayer.call of <bert.embeddings.BertEmbeddingsLayer object at 0x7ff789fff6d8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method PositionEmbeddingLayer.call of <bert.embeddings.PositionEmbeddingLayer object at 0x7ff7898d6080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbeddingLayer.call of <bert.embeddings.PositionEmbeddingLayer object at 0x7ff7898d6080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method PositionEmbeddingLayer.call of <bert.embeddings.PositionEmbeddingLayer object at 0x7ff7898d6080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbeddingLayer.call of <bert.embeddings.PositionEmbeddingLayer object at 0x7ff7898d6080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7898d62e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7898d62e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7898d62e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7898d62e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method TransformerEncoderLayer.call of <bert.transformer.TransformerEncoderLayer object at 0x7ff789fff2e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerEncoderLayer.call of <bert.transformer.TransformerEncoderLayer object at 0x7ff789fff2e8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method TransformerEncoderLayer.call of <bert.transformer.TransformerEncoderLayer object at 0x7ff789fff2e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerEncoderLayer.call of <bert.transformer.TransformerEncoderLayer object at 0x7ff789fff2e8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ec828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ec828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ec828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ec828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7898d9208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7898d9208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7898d9208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7898d9208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff7898f1320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff7898f1320>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff7898f1320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff7898f1320>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7898e9080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7898e9080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7898e9080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7898e9080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7898b2e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7898b2e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7898b2e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7898b2e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7898d9518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7898d9518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7898d9518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7898d9518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7898a3898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7898a3898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7898a3898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7898a3898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ecb38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ecb38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ecb38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ecb38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7898f1cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7898f1cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7898f1cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7898f1cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff7898e54e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff7898e54e0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff7898e54e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff7898e54e0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78987aac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78987aac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78987aac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78987aac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789822668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789822668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789822668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789822668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7898f1dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7898f1dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7898f1dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7898f1dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff78981f2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff78981f2b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff78981f2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff78981f2b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ecba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ecba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ecba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ecba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff78994aac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff78994aac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff78994aac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff78994aac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff7898ddeb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff7898ddeb8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff7898ddeb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff7898ddeb8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7897df160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7897df160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7897df160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7897df160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7897a2b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7897a2b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7897a2b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7897a2b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78994ac18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78994ac18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78994ac18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78994ac18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789795278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789795278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789795278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789795278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ecf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ecf60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ecf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ecf60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff78a0484a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff78a0484a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff78a0484a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff78a0484a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff789767588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff789767588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff789767588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff789767588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78975e898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78975e898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78975e898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78975e898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789720940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789720940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789720940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789720940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789815358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789815358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789815358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789815358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff78971c7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff78971c7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff78971c7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff78971c7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ecda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ecda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ecda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ecda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7898f1550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7898f1550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7898f1550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7898f1550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff789710668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff789710668>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff789710668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff789710668>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7896d7668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7896d7668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7896d7668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7896d7668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff78969d6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff78969d6d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff78969d6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff78969d6d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78975e278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78975e278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78975e278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78975e278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789691208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789691208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789691208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789691208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ec550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ec550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ec550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ec550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff78975a9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff78975a9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff78975a9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff78975a9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff789708f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff789708f60>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff789708f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff789708f60>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789656978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789656978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789656978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789656978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789615d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789615d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789615d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789615d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789710cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789710cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789710cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789710cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7896879e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7896879e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7896879e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7896879e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ec160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ec160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ec160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ec160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7897083c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7897083c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7897083c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7897083c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff78987a0f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff78987a0f0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff78987a0f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff78987a0f0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78987ac50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78987ac50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78987ac50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78987ac50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7891c08d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7891c08d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7891c08d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7891c08d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78987aa20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78987aa20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78987aa20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78987aa20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7891b2048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7891b2048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7891b2048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7891b2048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ec4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ec4a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ec4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ec4a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7896d7c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7896d7c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7896d7c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7896d7c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff789180a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff789180a90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff789180a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff789180a90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78917dc18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78917dc18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78917dc18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78917dc18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7891388d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7891388d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7891388d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7891388d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7896150b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7896150b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7896150b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7896150b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789138c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789138c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789138c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789138c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ec390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ec390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ec390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898ec390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7891afc18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7891afc18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7891afc18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7891afc18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff7890faa20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff7890faa20>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff7890faa20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff7890faa20>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789131ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789131ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789131ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789131ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7890b7668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7890b7668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7890b7668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7890b7668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789180f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789180f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789180f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789180f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7890a8390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7890a8390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7890a8390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff7890a8390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898d3cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898d3cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898d3cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898d3cc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff78966a5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff78966a5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff78966a5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff78966a5f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff789077cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff789077cc0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff789077cc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff789077cc0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789077588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789077588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789077588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789077588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789033400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789033400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789033400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789033400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789205a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789205a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789205a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789205a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789023c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789023c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789023c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff789023c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898d3470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898d3470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898d3470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898d3470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7890b3b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7890b3b70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7890b3b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff7890b3b70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff78917d668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff78917d668>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff78917d668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff78917d668>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78917df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78917df98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78917df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff78917df98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff788fa6a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff788fa6a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff788fa6a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff788fa6a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789111358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789111358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789111358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff789111358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff788faf358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff788faf358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff788faf358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff788faf358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898e52b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898e52b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898e52b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SingleTransformerEncoderLayer.call of <bert.transformer.SingleTransformerEncoderLayer object at 0x7ff7898e52b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff789656080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff789656080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff789656080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerSelfAttentionLayer.call of <bert.transformer.TransformerSelfAttentionLayer object at 0x7ff789656080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff788f6a630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff788f6a630>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff788f6a630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <bert.attention.AttentionLayer object at 0x7ff788f6a630>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff788f6d6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff788f6d6a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff788f6d6a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff788f6d6a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff788f27d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff788f27d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff788f27d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff788f27d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7890300b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7890300b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7890300b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ProjectionLayer.call of <bert.transformer.ProjectionLayer object at 0x7ff7890300b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff788f17b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff788f17b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff788f17b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <params_flow.normalization.LayerNormalization object at 0x7ff788f17b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0XneYFweEmL"
      },
      "source": [
        "flat = tf.keras.layers.Flatten()(embed)\n",
        "image_inp = tf.keras.layers.Input(shape=(4096,))\n",
        "concat = tf.keras.layers.concatenate([image_inp,flat])\n",
        "# decoder_out = decoder(encoder_outputs,initial_state=[merged,merged])\n",
        "out = tf.keras.layers.Dense(2,kernel_initializer=initializers.he_normal(seed=42),activation='softmax')(concat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E-gSAhTeTzz"
      },
      "source": [
        "model = tf.keras.Model(inputs = [image_inp,ques_inp],outputs = out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP24kWx2eW3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5adb5630-e482-43ad-c9e0-02d96b9f26a1"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 24)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bert (BertModelLayer)           (None, 24, 768)      108890112   input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 4096)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 18432)        0           bert[1][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 22528)        0           input_6[0][0]                    \n",
            "                                                                 flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 2)            45058       concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 108,935,170\n",
            "Trainable params: 45,058\n",
            "Non-trainable params: 108,890,112\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntWhRWg0edSu"
      },
      "source": [
        "model.build(input_shape=[(None,4096),(None,24)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICkcbj6ceiMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3749f44-f956-4e5f-c0b0-0e49842a61c8"
      },
      "source": [
        "bert.load_bert_weights(l_bert, model_ckpt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done loading 196 BERT weights from: .models/uncased_L-12_H-768_A-12/uncased_L-12_H-768_A-12/bert_model.ckpt into <bert.model.BertModelLayer object at 0x7ff789ffaf98> (prefix:bert). Count of weights not found in the checkpoint was: [0]. Count of weights with mismatched shape: [0]\n",
            "Unused weights from checkpoint: \n",
            "\tbert/embeddings/token_type_embeddings\n",
            "\tbert/pooler/dense/bias\n",
            "\tbert/pooler/dense/kernel\n",
            "\tcls/predictions/output_bias\n",
            "\tcls/predictions/transform/LayerNorm/beta\n",
            "\tcls/predictions/transform/LayerNorm/gamma\n",
            "\tcls/predictions/transform/dense/bias\n",
            "\tcls/predictions/transform/dense/kernel\n",
            "\tcls/seq_relationship/output_bias\n",
            "\tcls/seq_relationship/output_weights\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgm1flx0hHy-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "130f5873-9f96-4469-c7f1-f68845128cf3"
      },
      "source": [
        "checkpoint = ModelCheckpoint(\"/content/drive/MyDrive/data/basic_model4.h5\",\n",
        "                             monitor=\"val_loss\",\n",
        "                             mode=\"min\",\n",
        "                             save_best_only = True,\n",
        "                             verbose=1)\n",
        "\n",
        "tensorboard = TensorBoard(log_dir='logs1',histogram_freq=1,write_grads=True)\n",
        "\n",
        "callbacks = [checkpoint,tensorboard]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Weight and gradient histograms not supported for eagerexecution, setting `histogram_freq` to `0`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qru7xD4eQ5NF",
        "outputId": "63d12042-676b-453e-acab-18dc314231a1"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\r\n",
        "\r\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "model.fit(train_dataset,   epochs=30, validation_data=(test_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Epoch 1/30\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.6830 - acc: 0.5000 - val_loss: 4.3695 - val_acc: 0.5882\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 4.0449 - acc: 0.5789 - val_loss: 1.1392 - val_acc: 0.4118\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.1208 - acc: 0.4737 - val_loss: 2.5710 - val_acc: 0.4118\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 2.0878 - acc: 0.4211 - val_loss: 0.8335 - val_acc: 0.5882\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.8279 - acc: 0.6053 - val_loss: 1.4562 - val_acc: 0.5882\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.3062 - acc: 0.6053 - val_loss: 0.6868 - val_acc: 0.5882\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.7334 - acc: 0.5526 - val_loss: 1.3421 - val_acc: 0.4118\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.1352 - acc: 0.4737 - val_loss: 0.7374 - val_acc: 0.5882\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6470 - acc: 0.6842 - val_loss: 1.1748 - val_acc: 0.5882\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.8746 - acc: 0.6053 - val_loss: 1.3277 - val_acc: 0.5882\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.0737 - acc: 0.6053 - val_loss: 0.6915 - val_acc: 0.5882\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6914 - acc: 0.6053 - val_loss: 0.8137 - val_acc: 0.4706\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.8926 - acc: 0.5000 - val_loss: 0.6794 - val_acc: 0.4706\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6510 - acc: 0.6053 - val_loss: 0.8745 - val_acc: 0.5882\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.5294 - acc: 0.7105 - val_loss: 1.0575 - val_acc: 0.5882\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.7649 - acc: 0.6316 - val_loss: 0.7857 - val_acc: 0.5882\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6400 - acc: 0.6842 - val_loss: 0.6801 - val_acc: 0.4118\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6187 - acc: 0.6579 - val_loss: 0.7232 - val_acc: 0.4706\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6857 - acc: 0.5789 - val_loss: 0.6758 - val_acc: 0.5882\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6676 - acc: 0.6053 - val_loss: 0.7696 - val_acc: 0.5882\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6232 - acc: 0.6579 - val_loss: 0.7205 - val_acc: 0.5882\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6044 - acc: 0.6579 - val_loss: 0.8083 - val_acc: 0.5882\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6711 - acc: 0.5789 - val_loss: 0.8441 - val_acc: 0.5294\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.5470 - acc: 0.6842 - val_loss: 0.6747 - val_acc: 0.5882\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4987 - acc: 0.7632 - val_loss: 0.7562 - val_acc: 0.5882\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.7215 - acc: 0.6316 - val_loss: 0.6826 - val_acc: 0.6471\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.5491 - acc: 0.7632 - val_loss: 0.7567 - val_acc: 0.4706\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.5800 - acc: 0.6316 - val_loss: 0.8363 - val_acc: 0.5882\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.5240 - acc: 0.6579 - val_loss: 0.6818 - val_acc: 0.6471\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4804 - acc: 0.7368 - val_loss: 0.7307 - val_acc: 0.5294\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff74d360128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFRJ_1eACMe-"
      },
      "source": [
        "#save model to the drive\r\n",
        "#import os\r\n",
        "#target_dir = '/content/drive/MyDrive/data/'\r\n",
        "#if not os.path.exists(target_dir):\r\n",
        "#  os.mkdir(target_dir)\r\n",
        "#model.save('/content/drive/MyDrive/data/bert_trained.h5')\r\n",
        "#model.save_weights('/content/drive/MyDrive/data/bert_weights.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf1G95-XmDlp"
      },
      "source": [
        "# **SUMMARY**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZDY3DwN2YZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e722f433-0032-49ae-fd21-7e314b73693a"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "    \n",
        "x = PrettyTable()\n",
        "\n",
        "x.field_names = [\"Model\",\"Model Type\",\"Train loss\",\"Test loss\",\"Train Accuracy\",\"Test Accuracy\"]\n",
        "\n",
        "x.add_row([ \"Model 1\",\"Using Glove\",0.6679,0.7345,0.6238,0.5406])\n",
        "x.add_row([ \"Model 2\", \"BERT Embeddings Model\",0.6934,0.6936,0.5546,0.5412])\n",
        "x.add_row([ \"Model 3\", \"Using Spacy\",0.1248,0.9531,0.9018,0.8068])\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+-----------------------+------------+-----------+----------------+---------------+\n",
            "|  Model  |       Model Type      | Train loss | Test loss | Train Accuracy | Test Accuracy |\n",
            "+---------+-----------------------+------------+-----------+----------------+---------------+\n",
            "| Model 1 |      Using Glove      |   0.6679   |   0.7345  |     0.6238     |     0.5406    |\n",
            "| Model 2 | BERT Embeddings Model |   0.6934   |   0.6936  |     0.5546     |     0.5412    |\n",
            "| Model 3 |      Using Spacy      |   0.1248   |   0.9531  |     0.9018     |     0.8068    |\n",
            "+---------+-----------------------+------------+-----------+----------------+---------------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}